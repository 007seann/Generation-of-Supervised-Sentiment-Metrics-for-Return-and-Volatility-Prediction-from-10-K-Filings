{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5de3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58d8e7",
   "metadata": {},
   "source": [
    "Get CIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c41e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QQQ_path = './update_and_only2025.csv'\n",
    "# QQQ_path = './test.csv'\n",
    "\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(QQQ_path, encoding = 'utf-8')\n",
    "    QQQ_cik = df['CIK'].drop_duplicates().tolist()\n",
    "    QQQ_ticker = df['Symbol'].tolist()\n",
    "    QQQ_cik_ticker = dict(zip(QQQ_cik, QQQ_ticker))\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(QQQ_path, encoding = 'ISO-8859-1')\n",
    "    QQQ_cik = df['CIK'].drop_duplicates().tolist()\n",
    "    QQQ_ticker = df['Symbol'].tolist()\n",
    "    QQQ_cik_ticker = dict(zip(QQQ_cik, QQQ_ticker))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754987e",
   "metadata": {},
   "source": [
    "Download Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79f1d569",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission_api(cik, ticker, doc_type, headers, start_date, end_date):\n",
    "    # SEC submissions URL\n",
    "    rss_url = f'https://data.sec.gov/submissions/CIK{cik}.json'\n",
    "\n",
    "    # Retrieve the filing data from SEC\n",
    "    sec_data = requests.get(url=rss_url, headers=headers)\n",
    "\n",
    "    filings = sec_data.json().get('filings', {}).get('recent', {})\n",
    "\n",
    "    entries = []\n",
    "\n",
    "    # Iterate over the filings and filter by type and date range\n",
    "    for i in range(len(filings['accessionNumber'])):\n",
    "        filing_date = pd.to_datetime(filings['filingDate'][i])\n",
    "        filing_type = filings['form'][i]\n",
    "\n",
    "\n",
    "        if filing_type == doc_type and start_date <= filing_date <= end_date:\n",
    "\n",
    "            accession_number = filings['accessionNumber'][i].replace('-', '')\n",
    "            filing_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/index.json\"\n",
    "\n",
    "            # Fetch the specific filing details\n",
    "            filing_response = requests.get(filing_href, headers=headers)\n",
    "\n",
    "            if filing_response.status_code == 200:\n",
    "                filing_json = filing_response.json()\n",
    "                for file in filing_json['directory']['item']:\n",
    "\n",
    "                    if file['name'].endswith('.htm'):\n",
    "                        if doc_type.lower() in file['name'] or '10k' in file['name'] or ticker.lower() in file['name']:\n",
    "                            if 'ex' not in file['name']:\n",
    "                                html_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/{file['name']}\"\n",
    "                                entries.append((html_href, filing_type, filing_date))\n",
    "\n",
    "                    \n",
    "    return entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "039feb0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "import pandas as pd\n",
    "\n",
    "class LimitRequest:\n",
    "    SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "\n",
    "    @retry(stop=stop_after_attempt(5), wait=wait_fixed(2))  # Retry up to 5 times with a 2-second delay\n",
    "    def _call_sec(url, headers):\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            return response\n",
    "        else:\n",
    "            response.raise_for_status()  # Raise exception for failed requests\n",
    "\n",
    "    @classmethod\n",
    "    def get(cls, url, headers):\n",
    "        return cls._call_sec(url, headers)\n",
    "\n",
    "\n",
    "\n",
    "def get_sec_data(cik, ticker, doc_type, headers, end_date, start_date):\n",
    "\n",
    "\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    # SEC XBRL data APIs\n",
    "    xbrl_url = f'https://data.sec.gov/api/xbrl/companyconcept/CIK{cik}/us-gaap/AccountsPayableCurrent.json'\n",
    "    sec_data = requests.get(url=xbrl_url, headers=headers)\n",
    "    entries = []\n",
    "    try: \n",
    "        units = sec_data.json().get('units', {}).get('USD', [])\n",
    "    except (ValueError, KeyError, requests.exceptions.RequestException) as e:\n",
    "        print(f\"Error: {e}\")\n",
    "        try:\n",
    "            return submission_api(cik, ticker, doc_type, headers, start_date, end_date)\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "    \n",
    "    for i in range(len(units)):\n",
    "        filing_date = pd.to_datetime(units[i]['filed'])\n",
    "        filing_type = units[i]['form']\n",
    "        filing_accn = units[i]['accn']\n",
    "        \n",
    "        if filing_type == doc_type.upper() and start_date <= filing_date <= end_date:\n",
    "\n",
    "            filing_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{filing_accn.replace('-', '')}/index.json\"\n",
    "            filing_response = requests.get(filing_href, headers=headers)\n",
    "\n",
    "            if filing_response.status_code == 200:\n",
    "                filing_json = filing_response.json()\n",
    "                for file in filing_json['directory']['item']:\n",
    "                    if file['name'].endswith('.htm'):\n",
    "                        if doc_type.lower() in file['name'] or \"\".join(doc_type.lower().split(\"-\")) in file['name'] or ticker.lower() in file['name']:\n",
    "                            if 'ex' not in file['name']:\n",
    "                                html_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{filing_accn.replace('-', '')}/{file['name']}\"\n",
    "\n",
    "                                entries.append((html_href, filing_type, filing_date))\n",
    "\n",
    "    entries = list(dict.fromkeys(entries))\n",
    "\n",
    "    return entries\n",
    "\n",
    "\n",
    "            \n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbda4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_type(doc):\n",
    "    \"\"\"\n",
    "    Return the document type lowercased\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        The document string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doc_type : str\n",
    "        The document type lowercased\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regex explaination : Here I am tryng to do a positive lookbehind\n",
    "    # (?<=a)b (positive lookbehind) matches the b (and only the b) in cab, but does not match bed or debt.\n",
    "    # More reference : https://www.regular-expressions.info/lookaround.html\n",
    "    \n",
    "    type_regex = re.compile(r'(?<=<TYPE>)\\w+[^\\n]+') # gives out \\w\n",
    "    type_idx = re.search(type_regex, doc).group(0)\n",
    "    return type_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b481e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_format(doc):\n",
    "    \"\"\"\n",
    "    Return the document type lowercased\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        The document string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doc_type : str\n",
    "        The document type lowercased\n",
    "    \"\"\"\n",
    "    \n",
    "    format_regex = re.compile(r'(?<=<FILENAME>)\\w+[^\\n]+') # gives out \\w\n",
    "    doc_type  = re.search(format_regex, doc).group(0).lower()\n",
    "    if doc_type.endswith((\".htm\", \".html\")):\n",
    "        return 'HTML'\n",
    "    if doc_type.endswith(\".txt\"):\n",
    "        return 'TXT'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7419ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_documents(text):\n",
    "    document_start_regex = re.compile(r'<DOCUMENT>')\n",
    "    document_end_regex = re.compile(r'<\\/DOCUMENT>')\n",
    "    \n",
    "    document_start_indices = [match.start() for match in document_start_regex.finditer(text)]\n",
    "    document_end_indices = [match.start() for match in document_end_regex.finditer(text)]\n",
    "    \n",
    "    documents = []\n",
    "    for start_index, end_index in zip(document_start_indices, document_end_indices):\n",
    "        document = text[start_index:end_index]\n",
    "        documents.append(document)\n",
    "        \n",
    "    # If the filing is written in the XBRL content\n",
    "    if not documents:\n",
    "        # Parse the XBRL content\n",
    "        documents.append(text)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f9fdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def download_fillings(ciks_tickers, root_folder, doc_type, headers, end_date=datetime.datetime.now(), start_date = '1990-01-01'):\n",
    "    \n",
    "    for idx, (cik, ticker) in enumerate(ciks_tickers.items()):\n",
    "\n",
    "        cik = str(cik).zfill(10)\n",
    "        report_info = get_sec_data(cik, ticker, doc_type, headers, end_date=end_date, start_date=start_date)\n",
    "\n",
    "        # check if 10-K exists, otherwise skip it\n",
    "        if not report_info:\n",
    "            continue\n",
    "        else:\n",
    "            folder_path = os.path.join(root_folder, cik)\n",
    "            if not os.path.exists(folder_path):\n",
    "                os.makedirs(folder_path)\n",
    "\n",
    "        for index_url, _ , file_date in tqdm(report_info, desc='Downloading {} Fillings'.format(cik), unit='filling'):\n",
    "            file_date = file_date.strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "            file = LimitRequest.get(url=index_url, headers=headers)\n",
    "\n",
    "\n",
    "            file_name = os.path.join(folder_path, file_date + '.html')\n",
    "            with open(file_name,'w+') as f:\n",
    "                f.write(file.text)\n",
    "            f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdbf05",
   "metadata": {},
   "source": [
    "Report starts from 2006; parts of 2005 reports don't have item1A <br>\n",
    "Only for 10-k reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3ad4c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001652044 Fillings: 100%|██████████| 10/10 [00:02<00:00,  3.96filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001067983 Fillings: 100%|██████████| 8/8 [00:02<00:00,  3.28filling/s]\n",
      "Downloading 0001321655 Fillings: 100%|██████████| 5/5 [00:01<00:00,  4.11filling/s]\n",
      "Downloading 0001535527 Fillings: 100%|██████████| 6/6 [00:01<00:00,  3.23filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001996810 Fillings: 100%|██████████| 1/1 [00:00<00:00,  3.71filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001404912 Fillings: 100%|██████████| 11/11 [00:04<00:00,  2.29filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000766704 Fillings: 100%|██████████| 8/8 [00:03<00:00,  2.31filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001858681 Fillings: 100%|██████████| 2/2 [00:00<00:00,  2.02filling/s]\n",
      "Downloading 0001327811 Fillings: 100%|██████████| 12/12 [00:04<00:00,  2.69filling/s]\n",
      "Downloading 0001692819 Fillings: 100%|██████████| 2/2 [00:00<00:00,  2.41filling/s]\n",
      "Downloading 0001375365 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.79filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001811074 Fillings: 100%|██████████| 6/6 [00:01<00:00,  3.01filling/s]\n",
      "Downloading 0001175454 Fillings: 100%|██████████| 9/9 [00:03<00:00,  2.66filling/s]\n",
      "Downloading 0001609711 Fillings: 100%|██████████| 17/17 [00:07<00:00,  2.39filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000910521 Fillings: 100%|██████████| 9/9 [00:03<00:00,  2.74filling/s]\n",
      "Downloading 0001069202 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.59filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000765880 Fillings: 100%|██████████| 7/7 [00:02<00:00,  2.37filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001754301 Fillings: 100%|██████████| 3/3 [00:01<00:00,  2.34filling/s]\n",
      "Downloading 0001564708 Fillings: 100%|██████████| 6/6 [00:02<00:00,  2.80filling/s]\n",
      "Downloading 0001725057 Fillings: 100%|██████████| 6/6 [00:02<00:00,  2.54filling/s]\n",
      "Downloading 0000922621 Fillings: 100%|██████████| 1/1 [00:00<00:00,  1.72filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000014693 Fillings: 100%|██████████| 7/7 [00:04<00:00,  1.63filling/s]\n",
      "Downloading 0001745999 Fillings: 100%|██████████| 4/4 [00:03<00:00,  1.05filling/s]\n",
      "Downloading 0000798354 Fillings: 100%|██████████| 13/13 [00:04<00:00,  2.98filling/s]\n",
      "Downloading 0000216228 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.35filling/s]\n",
      "Downloading 0001163165 Fillings: 100%|██████████| 12/12 [00:05<00:00,  2.38filling/s]\n",
      "Downloading 0000093410 Fillings: 100%|██████████| 13/13 [00:06<00:00,  1.90filling/s]\n",
      "Downloading 0000064040 Fillings: 100%|██████████| 13/13 [00:03<00:00,  3.33filling/s]\n",
      "Downloading 0000101829 Fillings: 100%|██████████| 8/8 [00:02<00:00,  3.77filling/s]\n",
      "Downloading 0001618921 Fillings: 100%|██████████| 10/10 [00:03<00:00,  3.23filling/s]\n",
      "Downloading 0001109357 Fillings: 100%|██████████| 7/7 [00:02<00:00,  2.41filling/s]\n",
      "Downloading 0001130310 Fillings: 100%|██████████| 16/16 [00:06<00:00,  2.49filling/s]\n",
      "Downloading 0000068505 Fillings: 100%|██████████| 15/15 [00:05<00:00,  2.55filling/s]\n",
      "Downloading 0000072903 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.66filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000753308 Fillings: 100%|██████████| 9/9 [00:06<00:00,  1.47filling/s]\n",
      "Downloading 0000004281 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.63filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000060086 Fillings: 100%|██████████| 9/9 [00:03<00:00,  2.65filling/s]\n",
      "Downloading 0000047217 Fillings: 100%|██████████| 13/13 [00:05<00:00,  2.37filling/s]\n",
      "Downloading 0000004447 Fillings: 100%|██████████| 13/13 [00:04<00:00,  2.73filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001281761 Fillings: 100%|██████████| 9/9 [00:02<00:00,  3.06filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000036966 Fillings: 100%|██████████| 8/8 [00:02<00:00,  2.79filling/s]\n",
      "Downloading 0001583708 Fillings: 100%|██████████| 3/3 [00:00<00:00,  4.31filling/s]\n",
      "Downloading 0000026172 Fillings: 100%|██████████| 15/15 [00:08<00:00,  1.82filling/s]\n",
      "Downloading 0000031791 Fillings: 100%|██████████| 13/13 [00:04<00:00,  2.92filling/s]\n",
      "Downloading 0000008670 Fillings: 100%|██████████| 15/15 [00:05<00:00,  2.85filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000019617 Fillings: 100%|██████████| 1/1 [00:00<00:00,  2.58filling/s]\n",
      "Downloading 0000039899 Fillings: 100%|██████████| 13/13 [00:04<00:00,  2.97filling/s]\n",
      "Downloading 0001059556 Fillings: 100%|██████████| 15/15 [00:04<00:00,  3.09filling/s]\n",
      "Downloading 0000009389 Fillings: 100%|██████████| 15/15 [00:04<00:00,  3.27filling/s]\n",
      "Downloading 0000024545 Fillings: 100%|██████████| 13/13 [00:04<00:00,  3.12filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000086312 Fillings: 100%|██████████| 34/34 [00:11<00:00,  2.89filling/s]\n",
      "Downloading 0000018926 Fillings: 100%|██████████| 13/13 [00:04<00:00,  2.74filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000315293 Fillings: 100%|██████████| 15/15 [00:04<00:00,  3.16filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000320335 Fillings: 100%|██████████| 10/10 [00:03<00:00,  2.75filling/s]\n",
      "Downloading 0000701985 Fillings: 100%|██████████| 13/13 [00:04<00:00,  3.14filling/s]\n",
      "Downloading 0000732712 Fillings: 100%|██████████| 15/15 [00:04<00:00,  3.55filling/s]\n",
      "Downloading 0000732717 Fillings: 100%|██████████| 1752/1752 [11:21<00:00,  2.57filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000895421 Fillings: 100%|██████████| 2/2 [00:00<00:00,  3.74filling/s]\n",
      "Downloading 0000793952 Fillings: 100%|██████████| 15/15 [00:04<00:00,  3.16filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000092230 Fillings: 100%|██████████| 5/5 [00:01<00:00,  3.61filling/s]\n",
      "Downloading 0001701605 Fillings: 100%|██████████| 9/9 [00:02<00:00,  3.20filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000316709 Fillings: 100%|██████████| 5/5 [00:01<00:00,  3.17filling/s]\n",
      "Downloading 0000849399 Fillings: 100%|██████████| 11/11 [00:03<00:00,  3.24filling/s]\n",
      "Downloading 0000712515 Fillings: 100%|██████████| 16/16 [00:05<00:00,  2.86filling/s]\n",
      "Downloading 0000813828 Fillings: 100%|██████████| 11/11 [00:04<00:00,  2.69filling/s]\n",
      "Downloading 0000794367 Fillings: 100%|██████████| 1365/1365 [09:38<00:00,  2.36filling/s]\n",
      "Downloading 0000887396 Fillings: 100%|██████████| 6/6 [00:02<00:00,  2.92filling/s]\n",
      "Downloading 0001466258 Fillings: 100%|██████████| 18/18 [00:05<00:00,  3.27filling/s]\n",
      "Downloading 0001140859 Fillings: 100%|██████████| 10/10 [00:04<00:00,  2.24filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001116132 Fillings: 100%|██████████| 14/14 [00:05<00:00,  2.53filling/s]\n",
      "Downloading 0001136869 Fillings: 100%|██████████| 13/13 [00:07<00:00,  1.80filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001156039 Fillings: 100%|██████████| 11/11 [00:03<00:00,  2.91filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001138118 Fillings: 100%|██████████| 10/10 [00:02<00:00,  3.59filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000052988 Fillings: 100%|██████████| 9/9 [00:03<00:00,  2.80filling/s]\n",
      "Downloading 0001103982 Fillings: 100%|██████████| 10/10 [00:03<00:00,  3.27filling/s]\n",
      "Downloading 0000202058 Fillings: 100%|██████████| 8/8 [00:02<00:00,  3.12filling/s]\n",
      "Downloading 0000858470 Fillings: 100%|██████████| 10/10 [00:03<00:00,  3.00filling/s]\n",
      "Downloading 0000072741 Fillings: 100%|██████████| 9/9 [00:06<00:00,  1.33filling/s]\n",
      "Downloading 0001075531 Fillings: 100%|██████████| 10/10 [00:03<00:00,  2.61filling/s]\n",
      "Downloading 0001521332 Fillings: 100%|██████████| 8/8 [00:02<00:00,  2.77filling/s]\n",
      "Downloading 0001530721 Fillings: 100%|██████████| 7/7 [00:02<00:00,  2.72filling/s]\n",
      "Downloading 0001326801 Fillings: 100%|██████████| 8/8 [00:02<00:00,  3.45filling/s]\n",
      "Downloading 0001336917 Fillings: 100%|██████████| 8/8 [00:03<00:00,  2.60filling/s]\n",
      "Downloading 0001670541 Fillings: 100%|██████████| 2/2 [00:00<00:00,  2.89filling/s]\n",
      "Downloading 0001140536 Fillings: 100%|██████████| 7/7 [00:02<00:00,  3.01filling/s]\n",
      "Downloading 0001478242 Fillings: 100%|██████████| 6/6 [00:01<00:00,  3.66filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001095073 Fillings: 100%|██████████| 10/10 [00:05<00:00,  1.92filling/s]\n",
      "Downloading 0000814547 Fillings: 100%|██████████| 10/10 [00:03<00:00,  3.03filling/s]\n",
      "Downloading 0001327567 Fillings: 100%|██████████| 7/7 [00:02<00:00,  3.08filling/s]\n",
      "Downloading 0001543151 Fillings: 100%|██████████| 1/1 [00:00<00:00,  3.90filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000048898 Fillings: 100%|██████████| 8/8 [00:02<00:00,  2.93filling/s]\n",
      "Downloading 0001069183 Fillings: 100%|██████████| 13/13 [00:05<00:00,  2.54filling/s]\n",
      "Downloading 0001316835 Fillings: 100%|██████████| 11/11 [00:03<00:00,  2.99filling/s]\n",
      "Downloading 0001145197 Fillings: 100%|██████████| 4/4 [00:01<00:00,  2.75filling/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0001393818 Fillings: 100%|██████████| 9/9 [00:02<00:00,  3.33filling/s]\n",
      "Downloading 0001397187 Fillings: 100%|██████████| 9/9 [00:02<00:00,  3.08filling/s]\n"
     ]
    }
   ],
   "source": [
    "root_folder = 'total_sp500_10k-html'\n",
    "doc_type = '10-K'\n",
    "headers = {'User-Agent': 'University of Edinburgh s2101369@ed.ac.uk'}\n",
    "start_date = '2011-01-01',\n",
    "end_date = datetime.datetime.now()\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "download_fillings(QQQ_cik_ticker, root_folder,doc_type,headers,end_date=end_date,start_date=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1579372",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(root_folder):\n\u001b[1;32m      7\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(root_folder)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdownload_fillings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQQQ_cik_ticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mroot_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[8], line 7\u001b[0m, in \u001b[0;36mdownload_fillings\u001b[0;34m(ciks_tickers, root_folder, doc_type, headers, end_date, start_date)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, (cik, ticker) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(ciks_tickers\u001b[38;5;241m.\u001b[39mitems()):\n\u001b[1;32m      6\u001b[0m     cik \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(cik)\u001b[38;5;241m.\u001b[39mzfill(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m     report_info \u001b[38;5;241m=\u001b[39m \u001b[43mget_sec_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcik\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdoc_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# check if 10-K exists, otherwise skip it\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m report_info:\n",
      "Cell \u001b[0;32mIn[4], line 50\u001b[0m, in \u001b[0;36mget_sec_data\u001b[0;34m(cik, ticker, doc_type, headers, end_date, start_date)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filing_type \u001b[38;5;241m==\u001b[39m doc_type\u001b[38;5;241m.\u001b[39mupper() \u001b[38;5;129;01mand\u001b[39;00m start_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m filing_date \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m end_date:\n\u001b[1;32m     49\u001b[0m     filing_href \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.sec.gov/Archives/edgar/data/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcik\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfiling_accn\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/index.json\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 50\u001b[0m     filing_response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfiling_href\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filing_response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m200\u001b[39m:\n\u001b[1;32m     53\u001b[0m         filing_json \u001b[38;5;241m=\u001b[39m filing_response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/requests/adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    483\u001b[0m     timeout \u001b[38;5;241m=\u001b[39m TimeoutSauce(connect\u001b[38;5;241m=\u001b[39mtimeout, read\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 486\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    487\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_proxy(conn)\n\u001b[1;32m    713\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 714\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    725\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    726\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n\u001b[1;32m    728\u001b[0m response_conn \u001b[38;5;241m=\u001b[39m conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/connectionpool.py:403\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raise_timeout(err\u001b[38;5;241m=\u001b[39me, url\u001b[38;5;241m=\u001b[39murl, timeout_value\u001b[38;5;241m=\u001b[39mconn\u001b[38;5;241m.\u001b[39mtimeout)\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/connectionpool.py:1053\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1053\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n\u001b[1;32m   1056\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1057\u001b[0m         (\n\u001b[1;32m   1058\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnverified HTTPS request is being made to host \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         InsecureRequestWarning,\n\u001b[1;32m   1064\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/connection.py:419\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_certs\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mca_cert_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mload_default_certs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    416\u001b[0m ):\n\u001b[1;32m    417\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs()\n\u001b[0;32m--> 419\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    430\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[38;5;66;03m# If we're using all defaults and the connection\u001b[39;00m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;66;03m# is TLSv1 or TLSv1.1 we throw a DeprecationWarning\u001b[39;00m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;66;03m# for the host.\u001b[39;00m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    436\u001b[0m     default_ssl_context\n\u001b[1;32m    437\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_version \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock\u001b[38;5;241m.\u001b[39mversion() \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTLSv1.1\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m    440\u001b[0m ):\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/util/ssl_.py:449\u001b[0m, in \u001b[0;36mssl_wrap_socket\u001b[0;34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[0m\n\u001b[1;32m    437\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    438\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn HTTPS request has been made, but the SNI (Server Name \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    439\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIndication) extension to TLS is not available on this platform. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    445\u001b[0m         SNIMissingWarning,\n\u001b[1;32m    446\u001b[0m     )\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m send_sni:\n\u001b[0;32m--> 449\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    453\u001b[0m     ssl_sock \u001b[38;5;241m=\u001b[39m _ssl_wrap_socket_impl(sock, context, tls_in_tls)\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/site-packages/urllib3/util/ssl_.py:493\u001b[0m, in \u001b[0;36m_ssl_wrap_socket_impl\u001b[0;34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[1;32m    492\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m server_hostname:\n\u001b[0;32m--> 493\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    495\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ssl_context\u001b[38;5;241m.\u001b[39mwrap_socket(sock)\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/ssl.py:500\u001b[0m, in \u001b[0;36mSSLContext.wrap_socket\u001b[0;34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[0m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    495\u001b[0m                 do_handshake_on_connect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    496\u001b[0m                 suppress_ragged_eofs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    497\u001b[0m                 server_hostname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, session\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    498\u001b[0m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[0;32m--> 500\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msslsocket_class\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msession\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/ssl.py:1073\u001b[0m, in \u001b[0;36mSSLSocket._create\u001b[0;34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[1;32m   1071\u001b[0m             \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1073\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mOSError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m):\n\u001b[1;32m   1075\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/miniconda3/envs/hons-project/lib/python3.8/ssl.py:1342\u001b[0m, in \u001b[0;36mSSLSocket.do_handshake\u001b[0;34m(self, block)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 1342\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sslobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1343\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1344\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msettimeout(timeout)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "root_folder = 'total_sp500_10q-html'\n",
    "doc_type = '10-Q'\n",
    "headers = {'User-Agent': 'University of Edinburgh s2101367@ed.ac.uk'}\n",
    "start_date = '2011-01-01',\n",
    "end_date = datetime.datetime.now()\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "download_fillings(QQQ_cik_ticker, root_folder,doc_type,headers,end_date=end_date,start_date=start_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142afcd0",
   "metadata": {},
   "source": [
    "# Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc69699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?import requests\n",
    "# import time\n",
    "# from tenacity import retry, stop_after_attempt, wait_fixed\n",
    "# import pandas as pd\n",
    "\n",
    "# class LimitRequest:\n",
    "#     SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "\n",
    "#     @retry(stop=stop_after_attempt(5), wait=wait_fixed(2))  # Retry up to 5 times with a 2-second delay\n",
    "#     def _call_sec(url, headers):\n",
    "#         response = requests.get(url, headers=headers)\n",
    "#         if response.status_code == 200:\n",
    "#             return response\n",
    "#         else:\n",
    "#             response.raise_for_status()  # Raise exception for failed requests\n",
    "\n",
    "#     @classmethod\n",
    "#     def get(cls, url, headers):\n",
    "#         return cls._call_sec(url, headers)\n",
    "\n",
    "\n",
    "\n",
    "# def get_sec_data(cik, ticker, doc_type, headers, end_date, start_date, start, count):\n",
    "\n",
    "\n",
    "#     start_date = pd.to_datetime(start_date)\n",
    "#     end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "#     # SEC submissions URL\n",
    "#     rss_url = f'https://data.sec.gov/submissions/CIK{cik}.json'\n",
    "#     print(rss_url)\n",
    "\n",
    "#     # Retrieve the filing data from SEC\n",
    "#     sec_data = requests.get(url=rss_url, headers=headers)\n",
    "\n",
    "#     filings = sec_data.json().get('filings', {}).get('recent', {})\n",
    "\n",
    "\n",
    "#     entries = []\n",
    "#     # print('filings-form', filings['form'])\n",
    "#     print('filing_date', filings['filingDate'][1000])\n",
    "#     # print('doc_type', doc_type)\n",
    "#     print('start_date', start_date)\n",
    "#     print('end_date', end_date)\n",
    "#     # Iterate over the filings and filter by type and date range\n",
    "#     print('len', len(filings['accessionNumber']))\n",
    "#     print('len-date', len(filings['filingDate']))\n",
    "\n",
    "#     print('len-form', filings['form'][1000])\n",
    "\n",
    "#     for i in range(len(filings['accessionNumber'])):\n",
    "#         filing_date = pd.to_datetime(filings['filingDate'][i])\n",
    "#         filing_type = filings['form'][i]\n",
    "\n",
    "#         # if start_date <= filing_date <= end_date:\n",
    "\n",
    "\n",
    "#         #     print('filing_date', filing_date)\n",
    "\n",
    "#         if filing_type == doc_type and start_date <= filing_date <= end_date:\n",
    "\n",
    "\n",
    "#             accession_number = filings['accessionNumber'][i].replace('-', '')\n",
    "#             filing_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/index.json\"\n",
    "#             print('filing_href', filing_href)\n",
    "#             # Fetch the specific filing details\n",
    "#             filing_response = requests.get(filing_href, headers=headers)\n",
    "\n",
    "#             if filing_response.status_code == 200:\n",
    "#                 filing_json = filing_response.json()\n",
    "#                 for file in filing_json['directory']['item']:\n",
    "\n",
    "#                     if file['name'].endswith('.htm'):\n",
    "#                         if doc_type.lower() in file['name'] or '10k' in file['name'] or ticker.lower() in file['name']:  # Find HTML document\n",
    "#                             html_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{accession_number}/{file['name']}\"\n",
    "#                             # with open('output.txt', 'a') as f:\n",
    "#                             #     f.write(html_href + \"\\n\")\n",
    "\n",
    "#                             entries.append((html_href, filing_type, filing_date))\n",
    "#                             # break  # Stop after finding the HTML file\n",
    "                    \n",
    "#     return entries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "065ccb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LimitRequest(object):\n",
    "#     SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "#     @sleep_and_retry\n",
    "#     @limits(calls=SEC_CALL_LIMIT['calls'], period=SEC_CALL_LIMIT['seconds'])\n",
    "#     def _call_sec(url,headers):\n",
    "#         return requests.get(url,headers=headers)\n",
    "    \n",
    "#     @classmethod\n",
    "#     def get(cls,url,headers):\n",
    "#         return cls._call_sec(url, headers)\n",
    "\n",
    "# def get_sec_data(cik, doc_type, headers, end_date, start_date, start, count):\n",
    "#     start_date = pd.to_datetime(start_date)\n",
    "#     end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "#     # Updated SEC API URL\n",
    "#     rss_url = f'https://data.sec.gov/submissions/CIK{cik}.json'\n",
    "    \n",
    "#     # Set proper headers to identify yourself to the SEC\n",
    "#     sec_data = requests.get(url=rss_url, headers=headers)\n",
    "#     filings = sec_data.json()['filings']['recent']\n",
    "\n",
    "    \n",
    "#     entries = []\n",
    "    \n",
    "#     # Loop through the filings and filter by the document type and date range\n",
    "#     for i in range(len(filings['accessionNumber'])):\n",
    "#         filing_date = pd.to_datetime(filings['filingDate'][i])\n",
    "#         filing_type = filings['form'][i]\n",
    "        \n",
    "#         if filing_type == doc_type and start_date <= filing_date <= end_date:\n",
    "#             filing_href = f\"https://www.sec.gov/Archives/edgar/data/{cik}/{filings['accessionNumber'][i].replace('-', '')}/index.json\"\n",
    "#             entries.append((filing_href, filing_type, filing_date))\n",
    "    \n",
    "#     return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667638e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oupdated API Call\n",
    "# class LimitRequest(object):\n",
    "#     SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "#     @sleep_and_retry\n",
    "#     @limits(calls=SEC_CALL_LIMIT['calls'], period=SEC_CALL_LIMIT['seconds'])\n",
    "#     def _call_sec(url,headers):\n",
    "#         return requests.get(url,headers=headers)\n",
    "    \n",
    "#     @classmethod\n",
    "#     def get(cls,url,headers):\n",
    "#         return cls._call_sec(url, headers)\n",
    "\n",
    "\n",
    "# def get_sec_data(cik, doc_type, headers,end_date, start_date, start, count):\n",
    "#     start_date = pd.to_datetime(start_date)\n",
    "#     end_date = pd.to_datetime(end_date)\n",
    "#     rss_url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany' \\\n",
    "#         '&CIK={}&type={}&start={}&count={}&owner=exclude&output=atom' \\\n",
    "#         .format(cik, doc_type, start, count)\n",
    "    \n",
    "#     sec_data = LimitRequest.get(url = rss_url,headers=headers)\n",
    "#     soup = BeautifulSoup(sec_data.content, 'xml')    \n",
    "#     entries = [\n",
    "#         (   entry.content.find('filing-href').getText(),\n",
    "#             entry.content.find('filing-type').getText(),\n",
    "#             entry.content.find('filing-date').getText())\n",
    "#         for entry in soup.find_all('entry')\n",
    "#         if pd.to_datetime(entry.content.find('filing-date').getText()) <= end_date and pd.to_datetime(entry.content.find('filing-date').getText()) >= start_date]  \n",
    "#     return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d37d4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# def get_document_xml(text):\n",
    "#     # Parse the XBRL content\n",
    "#     soup = BeautifulSoup(text, 'lxml')\n",
    "#     body_text = soup.body.get_text()\n",
    "    \n",
    "#     return body_text\n",
    "\n",
    "\n",
    "# headers = {'User-Agent': 'University of Edinburgh s2101368@ed.ac.uk'}\n",
    "# url = \"https://www.sec.gov/Archives/edgar/data/0000320193/000032019323000106/aapl-20230930.htm\"\n",
    "# url2 = \"https://www.sec.gov/Archives/edgar/data/0000320193/000032019317000070/a10-k20179302017.htm\"\n",
    "# file  = LimitRequest.get(url=url2, headers=headers)\n",
    "# with open('output1.html', 'w') as f:\n",
    "#     f.write(file.text)\n",
    "\n",
    "# # for document in get_documents(file.text):\n",
    "# #     with open('output5.html', 'w') as f:\n",
    "# #         f.write(document)\n",
    "\n",
    "\n",
    "# # Tester\n",
    "\n",
    "# root_folder = 'data'\n",
    "# doc_type = '10-K'\n",
    "# headers = {'User-Agent': 'University of Edinburgh s2101368@ed.ac.uk'}\n",
    "# start_date = '2006-01-01',\n",
    "# end_date = datetime.datetime.now()\n",
    "# for idx, (cik, ticker) in enumerate(QQQ_cik_ticker.items()):\n",
    "\n",
    "#         cik = str(cik).zfill(10)\n",
    "\n",
    "#         repo = get_sec_data(cik, ticker, doc_type, headers, end_date, start_date)\n",
    "#         print(repo)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hons-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
