{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c5de3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "from ratelimit import limits, sleep_and_retry\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from collections import Counter\n",
    "import re\n",
    "import csv\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d58d8e7",
   "metadata": {},
   "source": [
    "Get CIKs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f526979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP500_path = './constituents.csv'\n",
    "# df = pd.read_csv(SP500_path)\n",
    "# SP500_cik = df['CIK'].drop_duplicates().tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3c41e6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "QQQ_path = './QQQ_constituents.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(QQQ_path, encoding = 'utf-8')\n",
    "    QQQ_cik = df['CIK'].drop_duplicates().tolist()\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(QQQ_path, encoding = 'ISO-8859-1')\n",
    "    QQQ_cik = df['CIK'].drop_duplicates().tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2754987e",
   "metadata": {},
   "source": [
    "Download Reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d358486",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LimitRequest(object):\n",
    "    SEC_CALL_LIMIT = {'calls': 10, 'seconds': 1}\n",
    "    @sleep_and_retry\n",
    "    @limits(calls=SEC_CALL_LIMIT['calls'], period=SEC_CALL_LIMIT['seconds'])\n",
    "    def _call_sec(url,headers):\n",
    "        return requests.get(url,headers=headers)\n",
    "    \n",
    "    @classmethod\n",
    "    def get(cls,url,headers):\n",
    "        return cls._call_sec(url, headers)\n",
    "\n",
    "\n",
    "def get_sec_data(cik, doc_type, headers,end_date, start_date, start, count):\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    rss_url = 'https://www.sec.gov/cgi-bin/browse-edgar?action=getcompany' \\\n",
    "        '&CIK={}&type={}&start={}&count={}&owner=exclude&output=atom' \\\n",
    "        .format(cik, doc_type, start, count)\n",
    "    \n",
    "    sec_data = LimitRequest.get(url = rss_url,headers=headers)\n",
    "    soup = BeautifulSoup(sec_data.content, 'xml')    \n",
    "    entries = [\n",
    "        (   entry.content.find('filing-href').getText(),\n",
    "            entry.content.find('filing-type').getText(),\n",
    "            entry.content.find('filing-date').getText())\n",
    "        for entry in soup.find_all('entry')\n",
    "        if pd.to_datetime(entry.content.find('filing-date').getText()) <= end_date and pd.to_datetime(entry.content.find('filing-date').getText()) >= start_date]  \n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9dbda4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_type(doc):\n",
    "    \"\"\"\n",
    "    Return the document type lowercased\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        The document string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doc_type : str\n",
    "        The document type lowercased\n",
    "    \"\"\"\n",
    "    \n",
    "    # Regex explaination : Here I am tryng to do a positive lookbehind\n",
    "    # (?<=a)b (positive lookbehind) matches the b (and only the b) in cab, but does not match bed or debt.\n",
    "    # More reference : https://www.regular-expressions.info/lookaround.html\n",
    "    \n",
    "    type_regex = re.compile(r'(?<=<TYPE>)\\w+[^\\n]+') # gives out \\w\n",
    "    type_idx = re.search(type_regex, doc).group(0).lower()\n",
    "    return type_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2b481e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_document_format(doc):\n",
    "    \"\"\"\n",
    "    Return the document type lowercased\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : str\n",
    "        The document string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    doc_type : str\n",
    "        The document type lowercased\n",
    "    \"\"\"\n",
    "    \n",
    "    format_regex = re.compile(r'(?<=<FILENAME>)\\w+[^\\n]+') # gives out \\w\n",
    "    doc_type  = re.search(format_regex, doc).group(0).lower()\n",
    "    if doc_type.endswith((\".htm\", \".html\")):\n",
    "        return 'HTML'\n",
    "    if doc_type.endswith(\".txt\"):\n",
    "        return 'TXT'\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7419ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_documents(text):\n",
    "    document_start_regex = re.compile(r'<DOCUMENT>')\n",
    "    document_end_regex = re.compile(r'<\\/DOCUMENT>')\n",
    "    \n",
    "    document_start_indices = [match.start() for match in document_start_regex.finditer(text)]\n",
    "    document_end_indices = [match.start() for match in document_end_regex.finditer(text)]\n",
    "    \n",
    "    documents = []\n",
    "    for start_index, end_index in zip(document_start_indices, document_end_indices):\n",
    "        document = text[start_index:end_index]\n",
    "        documents.append(document)\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0f9fdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def download_fillings(ciks, root_folder, doc_type, headers, end_date=datetime.datetime.now(), start_date = '1990-01-01', start=0, count=60):\n",
    "    doc_type= doc_type.lower()\n",
    "    for cik in ciks:\n",
    "        cik = str(cik).zfill(10)\n",
    "        folder_path = os.path.join(root_folder, cik)\n",
    "        if not os.path.exists(folder_path):\n",
    "            os.makedirs(folder_path)\n",
    "        report_info = get_sec_data(cik, doc_type, headers, end_date=end_date, start_date=start_date, start=start, count=count)\n",
    "        for index_url, file_type, file_date in tqdm(report_info, desc='Downloading {} Fillings'.format(cik), unit='filling'):\n",
    "            if (file_type.lower() == doc_type):\n",
    "                file_url = index_url.replace('-index.htm', '.txt').replace('.txtl', '.txt')\n",
    "                file = LimitRequest.get(url=file_url, headers=headers)\n",
    "                for document in get_documents(file.text):\n",
    "                    if get_document_type(document) == doc_type and get_document_format(document) == 'HTML':\n",
    "                        file_name = os.path.join(folder_path, file_date + '.html')\n",
    "                        with open(file_name,'w+') as f:\n",
    "                            f.write(document)\n",
    "                        f.close()\n",
    "                    if get_document_type(document) == doc_type and get_document_format(document) == 'TXT':\n",
    "                        file_name = os.path.join(folder_path, file_date + '.txt')\n",
    "                        with open(file_name,'w+') as f:\n",
    "                            f.write(document)\n",
    "                        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acdbf05",
   "metadata": {},
   "source": [
    "Report starts from 2006; parts of 2005 reports don't have item1A <br>\n",
    "Only for 10-k reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3ad4c286",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 0000320193 Fillings: 100%|██████████| 19/19 [00:17<00:00,  1.09filling/s]\n",
      "Downloading 0000796343 Fillings: 100%|██████████| 19/19 [00:24<00:00,  1.32s/filling]\n",
      "Downloading 0000006281 Fillings: 100%|██████████| 18/18 [00:27<00:00,  1.51s/filling]\n",
      "Downloading 0000008670 Fillings: 100%|██████████| 18/18 [00:43<00:00,  2.41s/filling]\n",
      "Downloading 0000769397 Fillings: 100%|██████████| 18/18 [00:26<00:00,  1.45s/filling]\n",
      "Downloading 0000004904 Fillings: 100%|██████████| 18/18 [02:35<00:00,  8.66s/filling]\n",
      "Downloading 0000006951 Fillings: 100%|██████████| 19/19 [00:26<00:00,  1.40s/filling]\n",
      "Downloading 0000002488 Fillings: 100%|██████████| 18/18 [00:21<00:00,  1.20s/filling]\n",
      "Downloading 0000318154 Fillings: 100%|██████████| 20/20 [00:27<00:00,  1.39s/filling]\n",
      "Downloading 0001018724 Fillings: 100%|██████████| 19/19 [00:15<00:00,  1.21filling/s]\n",
      "Downloading 0001013462 Fillings: 100%|██████████| 21/21 [00:18<00:00,  1.12filling/s]\n",
      "Downloading 0001730168 Fillings: 100%|██████████| 6/6 [00:10<00:00,  1.75s/filling]\n",
      "Downloading 0000875045 Fillings: 100%|██████████| 19/19 [00:30<00:00,  1.61s/filling]\n",
      "Downloading 0001075531 Fillings: 100%|██████████| 19/19 [00:18<00:00,  1.04filling/s]\n",
      "Downloading 0001701605 Fillings: 100%|██████████| 6/6 [00:15<00:00,  2.51s/filling]\n",
      "Downloading 0000813672 Fillings: 100%|██████████| 20/20 [00:26<00:00,  1.31s/filling]\n",
      "Downloading 0001402057 Fillings: 100%|██████████| 14/14 [00:16<00:00,  1.19s/filling]\n",
      "Downloading 0001868275 Fillings: 100%|██████████| 2/2 [00:15<00:00,  7.91s/filling]\n",
      "Downloading 0001091667 Fillings: 100%|██████████| 19/19 [00:24<00:00,  1.29s/filling]\n",
      "Downloading 0001166691 Fillings: 100%|██████████| 18/18 [00:33<00:00,  1.88s/filling]\n",
      "Downloading 0000909832 Fillings: 100%|██████████| 21/21 [00:16<00:00,  1.25filling/s]\n",
      "Downloading 0000900075 Fillings: 100%|██████████| 21/21 [00:21<00:00,  1.01s/filling]\n",
      "Downloading 0000858877 Fillings: 100%|██████████| 18/18 [00:25<00:00,  1.40s/filling]\n",
      "Downloading 0001057352 Fillings: 100%|██████████| 19/19 [00:21<00:00,  1.13s/filling]\n",
      "Downloading 0000277948 Fillings: 100%|██████████| 19/19 [00:22<00:00,  1.17s/filling]\n",
      "Downloading 0000723254 Fillings: 100%|██████████| 19/19 [00:33<00:00,  1.77s/filling]\n",
      "Downloading 0001058290 Fillings: 100%|██████████| 18/18 [00:30<00:00,  1.70s/filling]\n",
      "Downloading 0000935703 Fillings: 100%|██████████| 21/21 [00:24<00:00,  1.18s/filling]\n",
      "Downloading 0001093557 Fillings: 100%|██████████| 20/20 [00:34<00:00,  1.74s/filling]\n",
      "Downloading 0000712515 Fillings: 100%|██████████| 19/19 [00:34<00:00,  1.82s/filling]\n",
      "Downloading 0001109357 Fillings: 100%|██████████| 19/19 [01:41<00:00,  5.36s/filling]\n",
      "Downloading 0001539838 Fillings: 100%|██████████| 13/13 [00:14<00:00,  1.10s/filling]\n",
      "Downloading 0000815556 Fillings: 100%|██████████| 20/20 [00:23<00:00,  1.19s/filling]\n",
      "Downloading 0001262039 Fillings: 100%|██████████| 17/17 [00:13<00:00,  1.25filling/s]\n",
      "Downloading 0001932393 Fillings: 100%|██████████| 1/1 [00:01<00:00,  1.07s/filling]\n",
      "Downloading 0000882095 Fillings: 100%|██████████| 19/19 [00:17<00:00,  1.11filling/s]\n",
      "Downloading 0001652044 Fillings: 100%|██████████| 10/10 [00:10<00:00,  1.02s/filling]\n",
      "Downloading 0000773840 Fillings: 100%|██████████| 18/18 [00:34<00:00,  1.91s/filling]\n",
      "Downloading 0000874716 Fillings: 100%|██████████| 18/18 [00:21<00:00,  1.22s/filling]\n",
      "Downloading 0001110803 Fillings: 100%|██████████| 19/19 [00:18<00:00,  1.04filling/s]\n",
      "Downloading 0000050863 Fillings: 100%|██████████| 18/18 [00:57<00:00,  3.21s/filling]\n",
      "Downloading 0000896878 Fillings: 100%|██████████| 18/18 [00:17<00:00,  1.03filling/s]\n",
      "Downloading 0001035267 Fillings: 100%|██████████| 18/18 [00:14<00:00,  1.26filling/s]\n",
      "Downloading 0001418135 Fillings: 100%|██████████| 16/16 [00:27<00:00,  1.73s/filling]\n",
      "Downloading 0001637459 Fillings: 100%|██████████| 8/8 [00:14<00:00,  1.82s/filling]\n",
      "Downloading 0000319201 Fillings: 100%|██████████| 18/18 [00:28<00:00,  1.57s/filling]\n",
      "Downloading 0000707549 Fillings: 100%|██████████| 18/18 [00:25<00:00,  1.39s/filling]\n",
      "Downloading 0001048286 Fillings: 100%|██████████| 19/19 [00:27<00:00,  1.44s/filling]\n",
      "Downloading 0000827054 Fillings: 100%|██████████| 20/20 [00:32<00:00,  1.63s/filling]\n",
      "Downloading 0001103982 Fillings: 100%|██████████| 20/20 [00:40<00:00,  2.04s/filling]\n",
      "Downloading 0001326801 Fillings: 100%|██████████| 13/13 [00:18<00:00,  1.42s/filling]\n",
      "Downloading 0000865752 Fillings: 100%|██████████| 20/20 [00:27<00:00,  1.35s/filling]\n",
      "Downloading 0001682852 Fillings: 100%|██████████| 6/6 [00:19<00:00,  3.19s/filling]\n",
      "Downloading 0000789019 Fillings: 100%|██████████| 18/18 [00:25<00:00,  1.43s/filling]\n",
      "Downloading 0000723125 Fillings: 100%|██████████| 18/18 [00:29<00:00,  1.63s/filling]\n",
      "Downloading 0001065280 Fillings: 100%|██████████| 20/20 [00:15<00:00,  1.26filling/s]\n",
      "Downloading 0001045810 Fillings: 100%|██████████| 19/19 [00:21<00:00,  1.11s/filling]\n",
      "Downloading 0001413447 Fillings: 100%|██████████| 4/4 [00:12<00:00,  3.02s/filling]\n",
      "Downloading 0000878927 Fillings: 100%|██████████| 19/19 [00:15<00:00,  1.26filling/s]\n",
      "Downloading 0001097864 Fillings: 100%|██████████| 18/18 [00:33<00:00,  1.86s/filling]\n",
      "Downloading 0000898173 Fillings: 100%|██████████| 19/19 [00:24<00:00,  1.27s/filling]\n",
      "Downloading 0000723531 Fillings: 100%|██████████| 19/19 [00:23<00:00,  1.23s/filling]\n",
      "Downloading 0000075362 Fillings: 100%|██████████| 18/18 [00:34<00:00,  1.90s/filling]\n",
      "Downloading 0000077476 Fillings: 100%|██████████| 18/18 [00:42<00:00,  2.37s/filling]\n",
      "Downloading 0001633917 Fillings: 100%|██████████| 8/8 [00:13<00:00,  1.66s/filling]\n",
      "Downloading 0000804328 Fillings: 100%|██████████| 19/19 [00:26<00:00,  1.40s/filling]\n",
      "Downloading 0000872589 Fillings: 100%|██████████| 19/19 [00:25<00:00,  1.32s/filling]\n",
      "Downloading 0000882835 Fillings: 100%|██████████| 19/19 [00:16<00:00,  1.14filling/s]\n",
      "Downloading 0000745732 Fillings: 100%|██████████| 18/18 [00:16<00:00,  1.08filling/s]\n",
      "Downloading 0000829224 Fillings: 100%|██████████| 19/19 [00:28<00:00,  1.52s/filling]\n",
      "Downloading 0000883241 Fillings: 100%|██████████| 22/22 [00:18<00:00,  1.18filling/s]\n",
      "Downloading 0001283699 Fillings: 100%|██████████| 18/18 [00:15<00:00,  1.19filling/s]\n",
      "Downloading 0001318605 Fillings: 100%|██████████| 17/17 [00:11<00:00,  1.53filling/s]\n",
      "Downloading 0000946581 Fillings: 100%|██████████| 20/20 [00:12<00:00,  1.61filling/s]\n",
      "Downloading 0000097476 Fillings: 100%|██████████| 18/18 [00:13<00:00,  1.32filling/s]\n",
      "Downloading 0001442145 Fillings: 100%|██████████| 14/14 [00:11<00:00,  1.23filling/s]\n",
      "Downloading 0000875320 Fillings: 100%|██████████| 18/18 [00:13<00:00,  1.34filling/s]\n",
      "Downloading 0001618921 Fillings: 100%|██████████| 12/12 [00:07<00:00,  1.61filling/s]\n",
      "Downloading 0001437107 Fillings: 100%|██████████| 16/16 [00:19<00:00,  1.21s/filling]\n",
      "Downloading 0000072903 Fillings: 100%|██████████| 18/18 [00:19<00:00,  1.11s/filling]\n",
      "Downloading 0001774585 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0000937966 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0000901832 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0001650107 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0001535527 Fillings: 100%|██████████| 4/4 [00:03<00:00,  1.20filling/s]\n",
      "Downloading 0001792789 Fillings: 100%|██████████| 3/3 [00:02<00:00,  1.47filling/s]\n",
      "Downloading 0001561550 Fillings: 100%|██████████| 4/4 [00:02<00:00,  1.53filling/s]\n",
      "Downloading 0001709048 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0001397187 Fillings: 100%|██████████| 16/16 [00:09<00:00,  1.74filling/s]\n",
      "Downloading 0001441816 Fillings: 100%|██████████| 6/6 [00:03<00:00,  1.57filling/s]\n",
      "Downloading 0001099590 Fillings: 100%|██████████| 17/17 [00:11<00:00,  1.42filling/s]\n",
      "Downloading 0001835632 Fillings: 100%|██████████| 2/2 [00:01<00:00,  1.08filling/s]\n",
      "Downloading 0001327567 Fillings: 100%|██████████| 12/12 [00:08<00:00,  1.34filling/s]\n",
      "Downloading 0001737806 Fillings: 0filling [00:00, ?filling/s]\n",
      "Downloading 0000908937 Fillings: 100%|██████████| 19/19 [00:12<00:00,  1.57filling/s]\n",
      "Downloading 0001353283 Fillings: 100%|██████████| 11/11 [00:07<00:00,  1.47filling/s]\n",
      "Downloading 0001650372 Fillings: 100%|██████████| 1/1 [00:02<00:00,  2.85s/filling]\n",
      "Downloading 0001671933 Fillings: 100%|██████████| 8/8 [00:04<00:00,  1.78filling/s]\n",
      "Downloading 0001327811 Fillings: 100%|██████████| 11/11 [00:07<00:00,  1.45filling/s]\n",
      "Downloading 0001713683 Fillings: 100%|██████████| 6/6 [00:04<00:00,  1.35filling/s]\n"
     ]
    }
   ],
   "source": [
    "root_folder = 'data'\n",
    "doc_type = '10-k'\n",
    "headers = {'User-Agent': 'UOE / 0.1'}\n",
    "start_date = '2006-01-01',\n",
    "end_date = datetime.datetime.now()\n",
    "if not os.path.exists(root_folder):\n",
    "    os.makedirs(root_folder)\n",
    "download_fillings(QQQ_cik,root_folder,doc_type,headers,end_date=end_date,start_date=start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe3deb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
