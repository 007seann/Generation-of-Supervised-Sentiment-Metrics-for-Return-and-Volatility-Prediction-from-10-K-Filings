[supervisord]
nodaemon=true
logfile=/opt/airflow/logs/supervisord.log
logfile_maxbytes=50MB
logfile_backups=10
loglevel=info
pidfile=/tmp/supervisord.pid
umask=0022


[program:airflow-webserver]
command=/home/airflow/.local/bin/airflow webserver --port 3000
user=airflow
autostart=true
autorestart=true
priority=10
stdout_logfile=/opt/airflow/logs/airflow-webserver.log
stderr_logfile=/opt/airflow/logs/airflow-webserver.err
startretries=10


[program:airflow-scheduler]
command=/home/airflow/.local/bin/airflow scheduler
user=airflow
autostart=true
autorestart=true
priority=15
stdout_logfile=/opt/airflow/logs/airflow-scheduler.log
stderr_logfile=/opt/airflow/logs/airflow-scheduler.err
startretries=10

[program:spark-master]
command=/opt/spark-3.2.1-bin-hadoop3.2/bin/spark-class org.apache.spark.deploy.master.Master
user=airflow
autostart=true
autorestart=true
priority=20

[program:hadoop-namenode]
command=/opt/hadoop-3.3.1/bin/hdfs --daemon start namenode
user=airflow
autostart=true
autorestart=false
priority=20
stdout_logfile=/opt/airflow/logs/hadoop-namenode.log
stderr_logfile=/opt/airflow/logs/hadoop-namenode.err
startretries=10

[program:hadoop-datanode]
command=/opt/hadoop-3.3.1/bin/hdfs --daemon start datanode
user=airflow
autostart=true
autorestart=false
priority=25
stdout_logfile=/opt/airflow/logs/hadoop-datanode.log
stderr_logfile=/opt/airflow/logs/hadoop-datanode.err
startretries=10

[program:hive-metastore]
command=/opt/hive-3.1.3-bin/bin/hive --service metastore
user=airflow
autostart=true
autorestart=true
priority=30
stdout_logfile=/opt/airflow/logs/hive-metastore.log
stderr_logfile=/opt/airflow/logs/hive-metastore.err
startretries=10

[program:hive-server2]
command=/opt/hive-3.1.3-bin/bin/hive --service hiveserver2
user=airflow
autostart=true
autorestart=true
priority=35
stdout_logfile=/opt/airflow/logs/hive-server2.log
stderr_logfile=/opt/airflow/logs/hive-server2.err
startretries=10

