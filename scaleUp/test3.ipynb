{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Load the data\n",
    "# Assuming sp500_constituents.csv has columns: 'Firm', 'EntryDate', 'ExitDate'\n",
    "df = pd.read_csv('../Code_4_SECfilings/sp500_constituents.csv')\n",
    "\n",
    "# Convert date columns to datetime format\n",
    "df['start'] = pd.to_datetime(df['start'], errors='coerce')\n",
    "df['ending'] = pd.to_datetime(df['ending'], errors='coerce')\n",
    "\n",
    "# Define the range of years we are interested in\n",
    "years = range(2006, 2025)\n",
    "\n",
    "# Dictionary to hold the yearly snapshots\n",
    "sp500_by_year = {}\n",
    "permno_to_ticker = {}\n",
    "for year in years:\n",
    "    # Define the start and end of each year\n",
    "    start_of_year = datetime(year, 1, 1)\n",
    "    end_of_year = datetime(year, 12, 31)\n",
    "    \n",
    "    # Filter firms active during the year, ensuring they only appear once per year by permno\n",
    "    active_firms = df[\n",
    "        (df['start'] <= end_of_year) & \n",
    "        ((df['ending'].isna()) | (df['ending'] >= start_of_year))\n",
    "    ].drop_duplicates(subset=['permno'])\n",
    "    \n",
    "    # Exclude entries where a firm was in and out within a partial year\n",
    "    # This step further removes any firms that had re-entries or overlaps in date ranges\n",
    "    active_firms = active_firms[\n",
    "        (active_firms['start'] <= start_of_year) | (active_firms['ending'] >= end_of_year)\n",
    "    ]\n",
    "\n",
    "    # Convert the resulting DataFrame of firms to a list of unique permnos\n",
    "    permno_to_ticker = dict(zip(active_firms['permno'], active_firms['ticker']))\n",
    "\n",
    "    # Store the list of active firms for the year\n",
    "    sp500_by_year[year] = permno_to_ticker\n",
    "    \n",
    "\n",
    "# print(sp500_by_year)\n",
    "# # Display the results for each year\n",
    "# for year, firms in sp500_by_year.items():\n",
    "#     print(f\"Year {year}: {len(firms)} firms\")\n",
    "#     # Uncomment below to see the list of firms per year\n",
    "#     print(firms.values())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '../Code_4_SECfilings/sp500_total_constituents.csv'\n",
    "df = pd.read_csv(path)\n",
    "reversed_dict = {}\n",
    "for year, firms in sp500_by_year.items():\n",
    "    reversed_dict[year] = {ticker: pernmo for pernmo, ticker in sp500_by_year[year].items()}\n",
    "    for permno, ticker in sp500_by_year[year].items():\n",
    "        if ticker in df[\"Symbol\"].tolist():\n",
    "            cik = df[df[\"Symbol\"] == ticker][\"CIK\"].values[0]\n",
    "            reversed_dict[year][ticker] = cik\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp500_by_year = reversed_dict.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6825, 14213)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/Users/apple/PROJECT/hons_project/data/SP500/analysis_reports/intermediate/batch_10.parquet\"\n",
    "batch_number = 10\n",
    "df = pd.read_parquet(path)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5897, 14213)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Year'] = df[\"Date\"].dt.year\n",
    "\n",
    "vaild_pairs = set()\n",
    "for year, firms in sp500_by_year.items():\n",
    "    for cik in firms.values():\n",
    "        cik = str(cik).zfill(10)\n",
    "        vaild_pairs.add((year, cik))\n",
    "df_filtered = df[df.apply(lambda row: (row[\"Year\"], row[\"_cik\"]) in vaild_pairs, axis=1)]\n",
    "df_filtered = df_filtered.drop(columns=[\"Year\"])\n",
    "df_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_parquet(f\"/Users/apple/PROJECT/hons_project/data/SP500/analysis_reports/filtered/batch_filtered_{batch_number}.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hons-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
